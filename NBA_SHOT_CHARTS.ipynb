{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit"
    },
    "interpreter": {
      "hash": "f499c09746ed89bb16a1ef7cbb581cc63f8572953d5a366b82ca25faa5a00be4"
    },
    "colab": {
      "name": "WORK_BOOK_V2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Exploratória e Previsão de Arremessos da NBA"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objetivo\r\n",
        "    Este projeto visa primeiramente, realizar uma análise exploratória dos dados obtidos das últimas 12 temporadas regulares da NBA (2009-10 a 2020-21) e treinar diferentes modelos de machine learning com o intuito de prever se um arremesso é bem-sucedido ou não.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conjunto de Dados\r\n",
        "    Os dados foram obtidos através da API da NBA, o script 'get_players_shot_charts.ipynb' criado e a planilha com os ID's dos jogadores pode ser encontrados em:\r\n",
        "    \r\n",
        "    - (https://github.com/ArthurPatricio/Analise_Exploratoria_e_Previsao_de_Arremessos_da_NBA)\r\n",
        "\r\n",
        "    Os conjuntos de dados foram salvos por temporada em arquivos .xlsx (Ex: 'nba_shots_2020-21')\r\n",
        "\r\n",
        "    O conjunto de dados é formado pelos arremessos de todos os jogadores que jogam atualmente na NBA durante as últimas 12 temporadas regulares da liga. Esse conjunto não nos fornece em totalidade os arremessos das temporadas anteriores a atual porém é suficiente para notar padrões e comportamentos que serão discutidos a seguir.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linguagem, Bibliotecas e Pacotes\r\n",
        "    O trabalho foi feito todo em Python 3. Abaixo, segue a listagem de todas bibliotecas e pacotes utilizados:\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Import Libs\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "import missingno as msno\r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "import plotly.express as px\r\n",
        "import matplotlib as mpl\r\n",
        "import time\r\n",
        "from matplotlib.patches import Circle, Rectangle, Arc, ConnectionPatch\r\n",
        "from matplotlib.patches import Polygon\r\n",
        "from matplotlib.collections import PatchCollection\r\n",
        "from matplotlib.colors import LinearSegmentedColormap, ListedColormap, BoundaryNorm\r\n",
        "from matplotlib.path import Path\r\n",
        "from matplotlib.patches import PathPatch"
      ],
      "outputs": [],
      "metadata": {
        "id": "GLUma1CdaqQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Import Libs\r\n",
        "\r\n",
        "from sklearn.feature_selection import VarianceThreshold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn import tree\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "import xgboost as xgb"
      ],
      "outputs": [],
      "metadata": {
        "id": "ltXTB0vpaqRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leitura dos Dados\r\n",
        "    As 12 planilhas foram importandas e inseridas em Dataframes utilizando a biblioteca pandas."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Read NBA Shots excel files\r\n",
        "\r\n",
        "nba_shots_2020_21 = pd.read_excel('nba_shots_2020-21.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2019_20 = pd.read_excel('nba_shots_2019-20.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2018_19 = pd.read_excel('nba_shots_2018-19.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2017_18 = pd.read_excel('nba_shots_2017-18.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2016_17 = pd.read_excel('nba_shots_2016-17.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2015_16 = pd.read_excel('nba_shots_2015-16.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2014_15 = pd.read_excel('nba_shots_2014-15.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2013_14 = pd.read_excel('nba_shots_2013-14.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2012_13 = pd.read_excel('nba_shots_2012-13.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2011_12 = pd.read_excel('nba_shots_2011-12.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2010_11 = pd.read_excel('nba_shots_2010-11.xlsx', engine='openpyxl')\r\n",
        "nba_shots_2009_10 = pd.read_excel('nba_shots_2009-10.xlsx', engine='openpyxl')"
      ],
      "outputs": [],
      "metadata": {
        "id": "EJSsgCRhaqQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada Dataframe tem a coluna \"Unnamed: 0\" retirada e a coluna \"SEASON_ID\" adicionada sendo inserida a respectiva temporada do Dataframe em questão."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2020_21\r\n",
        "\r\n",
        "nba_shots_2020_21.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2020_21['SEASON_ID'] = '2020-21'\r\n",
        "nba_shots_2020_21.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "PUkSPZZhaqQ9",
        "outputId": "3b9da2df-fa02-4330-c403-e102c983fc54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2019_20\r\n",
        "\r\n",
        "nba_shots_2019_20.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2019_20['SEASON_ID'] = '2019-20'\r\n",
        "nba_shots_2019_20.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "YeZ1-SAHaqQ-",
        "outputId": "1e07d56d-f618-4820-8e47-ecd48887b95a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2018_19\r\n",
        "\r\n",
        "nba_shots_2018_19.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2018_19['SEASON_ID'] = '2018-19'\r\n",
        "nba_shots_2018_19.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Y0R2c_vNaqQ-",
        "outputId": "07c66164-4416-4924-915b-5db79c12d118"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2017_18\r\n",
        "\r\n",
        "nba_shots_2017_18.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2017_18['SEASON_ID'] = '2017-18'\r\n",
        "nba_shots_2017_18.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2016_17\r\n",
        "\r\n",
        "nba_shots_2016_17.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2016_17['SEASON_ID'] = '2016-17'\r\n",
        "nba_shots_2016_17.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2015_16\r\n",
        "\r\n",
        "nba_shots_2015_16.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2015_16['SEASON_ID'] = '2015-16'\r\n",
        "nba_shots_2015_16.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2014_15\r\n",
        "\r\n",
        "nba_shots_2014_15.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2014_15['SEASON_ID'] = '2014-15'\r\n",
        "nba_shots_2014_15.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2013_14\r\n",
        "\r\n",
        "nba_shots_2013_14.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2013_14['SEASON_ID'] = '2013-14'\r\n",
        "nba_shots_2013_14.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2012_13\r\n",
        "\r\n",
        "nba_shots_2012_13.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2012_13['SEASON_ID'] = '2012-13'\r\n",
        "nba_shots_2012_13.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2011_12\r\n",
        "\r\n",
        "nba_shots_2011_12.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2011_12['SEASON_ID'] = '2011-12'\r\n",
        "nba_shots_2011_12.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2010_11\r\n",
        "\r\n",
        "nba_shots_2010_11.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2010_11['SEASON_ID'] = '2010-11'\r\n",
        "nba_shots_2010_11.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Drop \"Unnamed: 0\" column, Add \"SEASON_ID\" column in nba_shots_2009_10\r\n",
        "\r\n",
        "nba_shots_2009_10.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
        "nba_shots_2009_10['SEASON_ID'] = '2009-10'\r\n",
        "nba_shots_2009_10.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os 12 Dataframes são concatenados em um único novo Dataframe chamado 'nba_shots'."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Create nba_shots as a concatenation of the 10 Dataframes from each reagular season\r\n",
        "\r\n",
        "nba_shots = pd.concat([nba_shots_2020_21, nba_shots_2019_20, nba_shots_2018_19, nba_shots_2017_18, nba_shots_2016_17, nba_shots_2015_16, nba_shots_2014_15, nba_shots_2013_14,\r\n",
        "                        nba_shots_2012_13, nba_shots_2011_12, nba_shots_2010_11, nba_shots_2009_10], sort=False)\r\n",
        "\r\n",
        "nba_shots.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "imiei5zFaqQ_",
        "outputId": "ed77f1d3-db8b-417d-81cb-3fdc58c0f300"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Inicial de nba_shots\r\n",
        "\r\n",
        "    O dataset nba_shots possui 2401273 registros e 25 atributos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Get nba_shots dataframe shape\r\n",
        "\r\n",
        "nba_shots.shape"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRuMpbdgaqRA",
        "outputId": "86d764d8-2047-471a-9a7a-6b82c17878fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Get nba_shots dataframe columns\r\n",
        "\r\n",
        "nba_shots.columns"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHDNp4waqRB",
        "outputId": "0f1fb9ce-86b5-487e-f63e-cfe4a32a1944"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Get nba_shots dataframe describe\r\n",
        "\r\n",
        "nba_shots.describe()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Pv0oBW9uaqRB",
        "outputId": "b84f048b-ce7d-4b35-8803-8da4fb177923"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Get nba_shots dataframe info\r\n",
        "\r\n",
        "nba_shots.info()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tng8tFdBaqRC",
        "outputId": "bffb4575-1e8d-4678-fddb-4faf490e0b4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checagem de valores nulos\r\n",
        "    nba_shots não possui nenhum valor faltante.\r\n",
        "\r\n",
        "    Foi utilizado a biblioteca missingno para realizar a checagem."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Check for messing values in the nba_shots dataframe\r\n",
        "\r\n",
        "msno.matrix(nba_shots)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UMQQyXHaqRC",
        "outputId": "4cd05c17-2857-413d-da53-9401b8e41e26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relatório Pandas Profile\r\n",
        "\r\n",
        "    Foi gerado o 'Pandas Profile Report' que oferece uma análise extensa do conjunto de dados que está sendo abordado."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Generate and export as a .html file the Pandas Profile Report of the nba_shots dataframe\r\n",
        "\r\n",
        "profile_shots = ProfileReport(nba_shots, title ='nba_shots')\r\n",
        "profile_shots.to_file(\"nba_shots_pandas_profile_report.html\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "DeyWFj18aqRD",
        "outputId": "57b30765-0186-4d4e-ce88-111332cc455c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Show Profile Report in this notebook\r\n",
        "\r\n",
        "profile_shots.to_notebook_iframe()"
      ],
      "outputs": [],
      "metadata": {
        "id": "pp-AtvjNaqRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função para desenhar a quadra\r\n",
        "    A função 'create_court' abaixo foi obtida do seguinte artigo: \r\n",
        "    \r\n",
        "    - (https://towardsdatascience.com/make-a-simple-nba-shot-chart-with-python-e5d70db45d0d)\r\n",
        "\r\n",
        "    Esta função cria desenha uma quadra de basquete nas proporções da NBA utilizando matplotlib."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Function to draw basketball court\r\n",
        "\r\n",
        "def create_court(ax, color):\r\n",
        "    \r\n",
        "    # Short corner 3PT lines\r\n",
        "    ax.plot([-220, -220], [0, 140], linewidth=2, color=color)\r\n",
        "    ax.plot([220, 220], [0, 140], linewidth=2, color=color)\r\n",
        "    \r\n",
        "    # 3PT Arc\r\n",
        "    ax.add_artist(mpl.patches.Arc((0, 140), 440, 315, theta1=0, theta2=180, facecolor='none', edgecolor=color, lw=2))\r\n",
        "    \r\n",
        "    # Lane and Key\r\n",
        "    ax.plot([-80, -80], [0, 190], linewidth=2, color=color)\r\n",
        "    ax.plot([80, 80], [0, 190], linewidth=2, color=color)\r\n",
        "    ax.plot([-60, -60], [0, 190], linewidth=2, color=color)\r\n",
        "    ax.plot([60, 60], [0, 190], linewidth=2, color=color)\r\n",
        "    ax.plot([-80, 80], [190, 190], linewidth=2, color=color)\r\n",
        "    ax.add_artist(mpl.patches.Circle((0, 190), 60, facecolor='none', edgecolor=color, lw=2))\r\n",
        "    \r\n",
        "    # Rim\r\n",
        "    ax.add_artist(mpl.patches.Circle((0, 60), 15, facecolor='none', edgecolor=color, lw=2))\r\n",
        "    \r\n",
        "    # Backboard\r\n",
        "    ax.plot([-30, 30], [40, 40], linewidth=2, color=color)\r\n",
        "    \r\n",
        "    # Remove ticks\r\n",
        "    ax.set_xticks([])\r\n",
        "    ax.set_yticks([])\r\n",
        "    \r\n",
        "    # Set axis limits\r\n",
        "    ax.set_xlim(-250, 250)\r\n",
        "    ax.set_ylim(0, 470)\r\n",
        "\r\n",
        "    # General plot parameters\r\n",
        "    #mpl.rcParams['font.family'] = 'Avenir'\r\n",
        "    mpl.rcParams['font.size'] = 18\r\n",
        "    mpl.rcParams['axes.linewidth'] = 2\r\n",
        "    \r\n",
        "    return ax\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "VqgmErDUaqRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise Exploratória\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Arremessos por Jogador\r\n",
        "    De ínicio foram plotados todos os arremessos tentados na temporada 2020-21 de 3 atletas da liga (James Harden, Stephen Curry e Nikola Jokic). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# JAMES HARDEN 2020-21 REGULAR SEASON SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Shots Scatter Plots\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'James Harden')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'James Harden')]['LOC_Y'] +60, marker = \"o\", color = \"Green\")\r\n",
        "\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'James Harden')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'James Harden')]['LOC_Y'] +60, marker = \"x\", color = \"Red\")\r\n",
        "\r\n",
        "plt.title('JAMES HARDEN 2020-21 REGULAR SEASON SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Zx-EKedWaqRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SEPHEN CURRY 2020-21 REGULAR SEASON SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'Stephen Curry')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'Stephen Curry')]['LOC_Y'] +60, marker = \"o\", color = \"Green\")\r\n",
        "\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'Stephen Curry')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'Stephen Curry')]['LOC_Y'] +60, marker = \"x\", color = \"Red\")\r\n",
        "\r\n",
        "plt.title('STEPHEN CURRY 2020-21 REGULAR SEASON SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ya09Ht6daqRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# NIKOLA JOKIC 2020-21 REGULAR SEASON SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'Nikola Jokic')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1) & (nba_shots['PLAYER_NAME'] == 'Nikola Jokic')]['LOC_Y'] +60, marker = \"o\", color = \"Green\")\r\n",
        "\r\n",
        "ax.scatter(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'Nikola Jokic')]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==0) & (nba_shots['PLAYER_NAME'] == 'Nikola Jokic')]['LOC_Y'] +60, marker = \"x\", color = \"Red\")\r\n",
        "\r\n",
        "plt.title('NIKOLA JOKIC 2020-21 REGULAR SEASON SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "54Go_BvuaqRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Arremessos Acertados por Temporada\r\n",
        "    Abaixo temos as plotagens utilizando a função .hexbin da biblioteca matplotlib.\r\n",
        "    \r\n",
        "    Nessa sequência de gráficos possível notar como o arremesso de 3 pontos se tornou cada vez mais o arremesso* mais popular na liga com o passar das temporadas.\r\n",
        "\r\n",
        "    *Arremessos não incluem ações ofensivas como bandejas e enterradas, que são feitas próximas da cesta e que continuam proeminentes na liga como pode ser notado em todas as imagens."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2020-21 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2020-21 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "NhIDe7dDaqRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2019-20 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2019-20') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2019-20') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2019-20 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nw2aPgbMaqRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2018-19 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2018-19') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2018-19') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2018-19 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "LyHnvvFDaqRG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2017-18 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2017-18') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2017-18') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2017-18 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2016-17 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2016-17') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2016-17') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2016-17 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2015-16 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2015-16') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2015-16') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2015-16 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2014-15 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2014-15') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2014-15') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2014-15 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2013-14 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2013-14') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2013-14') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2013-14 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2012-13 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2012-13') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2012-13') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2012-13 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2011-12 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2011-12') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2011-12') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2011-12 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2010-11 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2010-11') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2010-11') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2010-11 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2009-10 REGULAR SEASON MADE SHOTS\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(10, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "ax.hexbin(nba_shots[(nba_shots['SEASON_ID'] == '2009-10') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2009-10') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] +60, gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Greens')\r\n",
        "\r\n",
        "plt.title('2009-10 REGULAR SEASON MADE SHOTS', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Outras Visualizações de Arremessos\r\n",
        "    Os dados obtidos permitem ainda outras plotagens dos arremessos a seguir são mostradas 3 diferentes formas de enxergar os arremessos de acordo com sua posição em quadra."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arremessos acertados por região da quadra\r\n",
        "\r\n",
        "    O atributo 'SHOT_ZONE_AREA' oferece as regiões da quadra utilizadas nessa plotagem.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2020-21 REGULAR SEASON SHOTS MADE PER ZONE AREA\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(20, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "sns.scatterplot(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] + 60, hue = nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['SHOT_ZONE_AREA'])\r\n",
        "\r\n",
        "plt.title('2020-21 REGULAR SEASON SHOTS MADE PER ZONE AREA', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qk45C-R4aqRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arremessos acertados por zonas de distância.\r\n",
        "\r\n",
        "    O atributo 'SHOT_ZONE_RANGE' oferece as zonas por diferentes distâncias utilizadas nessa plotagem."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2020-21 REGULAR SEASON SHOTS MADE PER ZONE RANGE\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(20, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "sns.scatterplot(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] + 60, hue = nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['SHOT_ZONE_RANGE'])\r\n",
        "\r\n",
        "plt.title('2020-21 REGULAR SEASON SHOTS MADE PER ZONE RANGE', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arremessos acertados por regiões da quadra (simplificado).\r\n",
        "\r\n",
        "    O atributo 'SHOT_ZONE_BASIC' oferece regiões da quadra, diferentes das presentes em 'SHOT_ZONE_AREA', utilizadas nessa plotagem.\r\n",
        "\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 2020-21 REGULAR SEASON SHOTS MADE PER ZONE AREA (BASIC)\r\n",
        "\r\n",
        "# Create figure and axes\r\n",
        "fig = plt.figure(figsize=(20, 9))\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "\r\n",
        "# Draw court\r\n",
        "ax = create_court(ax, 'black')\r\n",
        "\r\n",
        "# Plot scatter of shots\r\n",
        "sns.scatterplot(nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_X'],\r\n",
        "            nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['LOC_Y'] + 60, hue = nba_shots[(nba_shots['SEASON_ID'] == '2020-21') & (nba_shots['SHOT_MADE_FLAG']==1)]['SHOT_ZONE_BASIC'])\r\n",
        "\r\n",
        "plt.title('2020-21 REGULAR SEASON SHOTS MADE PER ZONE AREA (BASIC)', fontsize = 20)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Distribuição de arrmessos por distância e tipo de Arremesso (2 ou 3 pontos)\r\n",
        "\r\n",
        "    O gráfico abaixo apresenta a distribuição dos arremessos das 12 temporadas em análise, pela distância em que os arremessos foram feitos e pelo tipo de arremesso (2 ou 3 pontos).\r\n",
        "\r\n",
        "    Nele nota-se ainda o predomínio dos arremessos de 2 pontos, bandejas ou enterradas feitos bem próximos da cesta. Com o arremesso de longa distância, de 3 pontos, já com quantidade considerável.\r\n",
        "\r\n",
        "    Nos gráficos a seguir  onde comparamos as distribuições da primeira e útima do nosso dataset, vemos que hoje, há o predomínio da bola lonfa, de 3 pontos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT DISTANCE DISTRIBUTION PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig1 = sns.histplot(data=nba_shots, x='SHOT_DISTANCE', hue = 'SHOT_TYPE')\r\n",
        "fig1.set_xlabel('SHOT_DISTANCE', fontsize=20)\r\n",
        "fig1.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig1.tick_params(labelsize=15)\r\n",
        "plt.title('SHOT DISTANCE DISTRIBUTION', fontsize = 20)\r\n",
        "plt.xlim(0,40)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "FaLDnIvRaqRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando as plotagens abaixo, distribuições tais como a anterior só que agora específicas para as temporadas 2009-10 e 2020-21, respectivamente primeira e última temporadas do nosso conjunto de dados, notamos com clareza a mudança no padrão das ações ofensivas com o passar dos anos. Arremessos de média distância deram espaço para os arremesos de 3 pontos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT DISTANCE DISTRIBUTION PLOT 2009-10 SEASON\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig2 = sns.histplot(data=nba_shots, \r\n",
        "                    x=nba_shots[nba_shots['SEASON_ID'] == '2009-10']['SHOT_DISTANCE'], \r\n",
        "                    hue = nba_shots[nba_shots['SEASON_ID'] == '2009-10']['SHOT_TYPE'])\r\n",
        "fig2.set_xlabel('SHOT_DISTANCE', fontsize=20)\r\n",
        "fig2.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig2.tick_params(labelsize=15)\r\n",
        "plt.title('SHOT DISTANCE DISTRIBUTION 2009-10 SEASON', fontsize = 20)\r\n",
        "plt.xlim(0,40)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT DISTANCE DISTRIBUTION PLOT 2020-21 SEASON\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig3 = sns.histplot(data=nba_shots, \r\n",
        "                    x=nba_shots[nba_shots['SEASON_ID'] == '2020-21']['SHOT_DISTANCE'], \r\n",
        "                    hue = nba_shots[nba_shots['SEASON_ID'] == '2020-21']['SHOT_TYPE'])\r\n",
        "fig3.set_xlabel('SHOT_DISTANCE', fontsize=20)\r\n",
        "fig3.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig3.tick_params(labelsize=15)\r\n",
        "plt.title('SHOT DISTANCE DISTRIBUTION 2020-21 SEASON', fontsize = 20)\r\n",
        "plt.xlim(0,40)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Tipos de Arremessos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico a seguir mostra todos os arremessos tentados nas 12 temporadas pelo tipo de arremesso tentado (2 ou 3 pontos)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig4 = sns.countplot(data=nba_shots, x='SHOT_TYPE', palette = 'husl')\r\n",
        "fig4.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig4.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig4.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE', fontsize = 20)\r\n",
        "for p in fig4.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig4.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "rcKFcJTbaqRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico a seguir mostra todos os arremessos tentados nas 12 temporadas pelo tipo de arremesso tentado (2 ou 3 pontos) e resultado do arremesso."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE (MADE/MISSED) BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig5 = sns.countplot(data=nba_shots, x='SHOT_TYPE', palette = 'husl', hue = 'EVENT_TYPE')\r\n",
        "fig5.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig5.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig5.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE (MADE/MISSED)', fontsize = 20)\r\n",
        "for p in fig5.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig5.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "HgNhjvUaaqRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análogo ao que foi feito com os gráficos de distribuição, como pode ser visto abaixo, plotando os gráficos de barra por tipo de arremesso vemos que proporcionalmente a quantidade de arremessos de 2 e 3 pontos é muito mais próxima na temporada 2020-21 do que era na temporada 2009-10."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig6 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['SEASON_ID'] == '2009-10']['SHOT_TYPE'], palette = 'husl')\r\n",
        "fig6.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig6.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig6.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE 2009-10 SEASON', fontsize = 20)\r\n",
        "for p in fig6.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig6.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig7 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['SEASON_ID'] == '2020-21']['SHOT_TYPE'], palette = 'husl')\r\n",
        "fig7.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig7.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig7.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE 2020-21 SEASON', fontsize = 20)\r\n",
        "for p in fig7.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig7.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Arremessos por Tipo de Acão ofensiva\r\n",
        "\r\n",
        "    O gráfico abaixo mostra todos os arremesoss tentados nas 10 temporadas pelo tipo de ação ofensiva.\r\n",
        "\r\n",
        "    Nele nota-se que o 'jump shot' (ou arremesso) é o tipo de arremesso mais tentado na liga.\r\n",
        "\r\n",
        "    Pare esclarecer a confusão que a tradução dos termos pode deixar, arremesso pode significar 'shot' que é um arremesso  qualquer ou 'jump shot' que é um tipo específico de arremesso. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT ACTION TYPE BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(45,12))\r\n",
        "fig8 = sns.countplot(data=nba_shots, x='ACTION_TYPE', palette = 'husl') \r\n",
        "fig8.set_xlabel('ACTION_TYPE', fontsize=20)\r\n",
        "fig8.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig8.tick_params(labelsize=20)\r\n",
        "fig8.tick_params(axis = 'x', rotation = 90)\r\n",
        "plt.title('SHOT ACTION TYPE', fontsize = 20)\r\n",
        "for p in fig8.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig8.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "QcIJau6zaqRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Arremessos por Período\r\n",
        "\r\n",
        "    Outra forma interessante de se enxergar a efetividade dos arremessos é através dos períodos de um jogo de basquete. Um jogo tem 4 períodos e se ao final o jogo permanecer empatado, períodos extra mais curtos, são jogados até que ao final de um deles um time esteja vencendo.\r\n",
        "\r\n",
        "    Abaixo podemos ver que média de acerto cai com o avanço dos períodos, algo que pode-se considerar esperado. Já que com o passar do jogo, cada arremesso tende a carregar maior importância, sendo esse um aspecto mental que pode afetar os atletas. Outro fator é o físico, quando mais se joga mais cansados estão os atletas, o que os leva em momentos a não conseguir performar o movimento do arremesso corretamente. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT PER GAME PERIOD BAR PLOT\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig5 = sns.countplot(data=nba_shots, x='PERIOD', palette = 'husl', hue = 'EVENT_TYPE')\r\n",
        "fig5.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig5.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig5.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE PER GAME PERIOD', fontsize = 20)\r\n",
        "for p in fig5.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig5.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Média Primeiro Período: 291535/(333488 + 291535) = 0,4664 -> 46,64%\r\n",
        "\r\n",
        "Média Segundo Período: 276689/(324187 + 276689) = 0,4605 -> 46,05%\r\n",
        " \r\n",
        "Média Terceiro Período: 268154/(320667 + 268154) = 0,4554 -> 45,54%\r\n",
        " \r\n",
        "Média Quarto Período: 253673/(316060 + 253673) = 0,4452 -> 44,52%"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previsão de Arremessos utilizando modelos de Machine Learming\r\n",
        "\r\n",
        "    A partir destre ponto o conjunto de dados foi tratado a fim de alimentar modelos de Machine Learning com o intuito de prever o resultado de arremessos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sub Conjuntos de Dados\r\n",
        "\r\n",
        "    Dada a dimensão do nosso conjunto principal de dados que possui, 2401273 registros e 25 atributos. Foi decidido trabalhar com os modelos de machine learning utilizando sub conjuntos de dados.\r\n",
        "\r\n",
        "    Foram criadas duas funções 'choose_player' e 'choose_season'. 'choose_player' permite criar um sub conjunto de dados de um jogador da NBA. 'choose_season' permite criar um sub conjunto de dados de uma temporada da NBA.\r\n",
        "\r\n",
        "    Em ambas os sub conjuntos sofrem as seguintes operações:\r\n",
        "    \r\n",
        "    * Redução de Dimensão: Os atributos 'PLAYER_NAME', 'EVENT_TYPE' e 'TEAM_NAME' são retirados por serem redundantes em informação fornecida com os atributos 'PLAYER_ID', 'SHOT_MADE_FLAG' e 'TEAM_ID' respectivamente.\r\n",
        "\r\n",
        "    * Dummy Coding: Aplicado nos seguintes atrobutos categóricos  'GRID_TYPE', 'ACTION_TYPE', 'SHOT_TYPE', 'SHOT_ZONE_BASIC', \r\n",
        "      'SHOT_ZONE_AREA', 'SHOT_ZONE_RANGE', 'HTM', 'VTM' e 'SEASON_ID'.\r\n",
        "\r\n",
        "    * Train/Test split: Os conjuntos de Treino e Teste foram criados com os seguintes parâmetros:\r\n",
        "\r\n",
        "      - Razão treino/teste igual a 0.2\r\n",
        "      - Random state igual a 100 para permitir reproducibilidade ods conjuntos de treino e teste.\r\n",
        "      - Estratificação ativada para permitir uma divisão equilibrada entre os resultados do sub conjunto de dados escolhido.\r\n",
        "\r\n",
        "    * Checagem e tratamento de atributos vom variância igual a zero: Foram calculadas as variâncias de todos os atributos e os com valor 0 foram retirados das bases de Treino e Teste.\r\n",
        "\r\n",
        "    * Normalização: Os dados das bases de Treino e Teste foram normalizados. É uma etapa fundamental pois o conjunto de dados possui atributos numéricos em escalas bastante distintas, como por exmplo 'TEAM_ID' e 'PERIOD'. Essa diferença pode levar os modelos a uma menor eficiência.\r\n",
        "\r\n",
        "\r\n",
        "  Para o treinamento dos modelos que virão a seguir, iremos trabalhar com o sub conjunto de arremessos do jogador Stephen Curry. Treinamentos também foram feitos utilizando sub conjuntos de uma temporada inteira (2020-21) e os resultados não se distanciaram significativamente dos resultados obtidos utilizando apenas os arremessos do jogador.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise exploratória do sub conjunto de dados\r\n",
        "\r\n",
        "    Decidido o sub conjunto de dados que iremos utilizar para o treinamento e avaliação dos nossos modelos, é interessante repetir agora algumas das avaliações que fizemos anteriormente, apenas considerando os arremessos do Stephen Curry."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como pode ser visto na distribuição de arremessos por distância e tipo apresentada abaixo. O jogador possui um perfil de arremessar preferencialmente bolas de 3 pontos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT DISTANCE DISTRIBUTION PLOT STEPHEN CURRY\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig9 = sns.histplot(data=nba_shots, \r\n",
        "                    x=nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['SHOT_DISTANCE'], \r\n",
        "                    hue = nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['SHOT_TYPE'])\r\n",
        "fig9.set_xlabel('SHOT_DISTANCE', fontsize=20)\r\n",
        "fig9.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig9.tick_params(labelsize=15)\r\n",
        "plt.title('SHOT DISTANCE DISTRIBUTION STEPHEN CURRY', fontsize = 20)\r\n",
        "plt.xlim(0,40)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos gráficos de barra abaixo, que mostram os arremessos divididos pelo tipo (2 e 3 pontos) e por tipo e resultado respsctivamente. Notamos que o Stephen Curry foge do comportamento visto nestes mesmos gráficos que foram plotados considerando o dataset inteiro.\r\n",
        "\r\n",
        "Em 12 temporadas, o atleta estreou na temporada 2009-10, Curry arremesou um pouco mais bolas de 2 do que de 3 e deve inverter essa ordem dentro das próximas temporadas visto que a diferença é de apenas 219 arremessos e que ele tem tentado mais arremessos de 3 do que de 2 nas últimas 6 temporadas.  \r\n",
        "\r\n",
        "Esses números eram algo impensável antes do surgimento do mesmo. Vale lembrar que ele já é considerado quase que unanimamente por mídia especializada e fãs, como o melhor arremessador de 3 pontos da história da liga. Tendo sob seu nome vários recordes como por exemplo, mais arremessos de 3 pontos acertados em uma temporada regular (2015-2016) e mais arremessos de 3 pontos acertados em playoffs (na história).[1]"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE BAR PLOT STEPHEN CURRY\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig10 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['SHOT_TYPE'], palette = 'husl')\r\n",
        "fig10.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig10.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig10.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE STEPHEN CURRY', fontsize = 20)\r\n",
        "for p in fig10.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig10.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE (MADE/MISSED) BAR PLOT STEPHEN CURRY\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig11 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['SHOT_TYPE'], \r\n",
        "                    palette = 'husl', \r\n",
        "                    hue = nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['EVENT_TYPE'])\r\n",
        "fig11.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig11.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig11.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE (MADE/MISSED) STEPHEN CURRY', fontsize = 20)\r\n",
        "for p in fig11.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig11.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apesar de sua extrema capacidade na bola de 3, Curry ainda sim acerta percentualmente mais bolas de 2 do que de 3, como pode ser visto no gráfico abaixo. \r\n",
        "\r\n",
        "Média nos arremessos de 2 pontos: 3508/(3248 + 3508) = 0,5192 -> 51,92%\r\n",
        "\r\n",
        "Media nos arremessos de 3 pontos: 2830/(3707 + 2830) = 0,4329 -> 43,29%\r\n",
        "\r\n",
        "Média geral: (3508 + 2830)/(3508 + 3248 + 2830 + 3707) = 0,4668 -> 46,68%\r\n",
        "\r\n",
        "A diferença nas médias é absolutamente normal dada a natureza do jogo de basquete, a bola de 3 é uma ação ofensiva de maior risco e maior recompensa. A média de 43,29% na carreira no arremesso de 3 é atualmente a sétima melhor marca na história da liga e considerando que Curry arremessa bem mais do que os 6 acima, isso torna o seu rendimento ainda mais impressionante. [2]"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoje, os times notam que esse maior risco vale ser encarado. Tendo em consideração as médias do Curry. Como calculado, ele acerta em média 51,92% dos seus arremessos de 2 pontos, em um cenário em que tente 10 desses arremessos, ele acertaria 5 e isso resultaria num total de 10 pontos. Já se fizer as mesmas 10 tentativas para a bola de 3, com sua média de 43,29%, acertaria 4 bolas que somariam um total de 12 pontos.\r\n",
        "\r\n",
        "Obviamente que esse cenário que ignora dezenas de fatores que levam ao sucesso ou não de um arremesso em um jogo oficial de basquete na NBA. Porém, essa lógica é a base do pensamento que levam hoje muitos dos times e sua comissões técnicas a priorizarem a bola de 3 mesmo que isso faça com que a média de acerto dos arremessos caia."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferente do que foi visto para o dataset geral, se analizarmos a performance de acerto de arremessos por período de jogo, Curry não aparenta seguir o mesmo padrão que o resto da liga, onde as médias de acerto caem com o avançar do jogo."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT PER GAME PERIOD BAR PLOT STEPHEN CURRY\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig12 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['PERIOD'],\r\n",
        "                        palette = 'husl', \r\n",
        "                        hue = nba_shots[nba_shots['PLAYER_NAME'] == 'Stephen Curry']['EVENT_TYPE'])\r\n",
        "fig12.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig12.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig12.tick_params(labelsize=20)\r\n",
        "fig12.legend(loc=1, title='EVENT_TYPE')\r\n",
        "plt.title('SHOT TYPE PER GAME PERIOD STEPHEN CURRY', fontsize = 20)\r\n",
        "for p in fig12.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig12.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Média Primeiro Período: 1891/(2078 + 1891) = 0,4764 -> 47,64%\r\n",
        "\r\n",
        "Média Segundo Período: 1337/(1429 + 1337) = 0,4834 -> 48,34%\r\n",
        " \r\n",
        "Média Terceiro Período: 1940/(2112 + 1940) = 0,4788 -> 47,88%\r\n",
        " \r\n",
        "Média Quarto Período: 1128/(1280 + 1128) = 0,4684 -> 46,84%"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função choose_player\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Due to the large amount of the dataset, everything past this point you be done per player. The function below creates a sub dataset from nba_shots with the data form the chosen player. \r\n",
        "\r\n",
        "def choose_player (player_name):\r\n",
        "    player_shots = nba_shots[nba_shots['PLAYER_NAME'] == player_name]\r\n",
        "    print(player_shots.head())\r\n",
        "    \r\n",
        "    # Dimensional Reduction: Columns PLAYER_ID and PLAYER_NAME carry the same type of information, PLAYER_NAME is going to be droped. \r\n",
        "    # The same happens to columns EVENT_TYPE and SHOT_MADE_FLAG, EVENT_TYPE is going to be droped.\r\n",
        "    # It also happens for TEAM_ID and TEAM_NAME, TEAM_NAME is going to be droped.\r\n",
        "\r\n",
        "    nba_shots_ml = player_shots.drop(['PLAYER_NAME', 'EVENT_TYPE', 'TEAM_NAME'], axis = 1)\r\n",
        "    \r\n",
        "    # Apply Dummy Coding to the categorial attributes of the dataset\r\n",
        "\r\n",
        "    categorical_columns = ['GRID_TYPE', 'ACTION_TYPE', 'SHOT_TYPE', 'SHOT_ZONE_BASIC', \r\n",
        "    'SHOT_ZONE_AREA', 'SHOT_ZONE_RANGE', 'HTM', 'VTM', 'SEASON_ID']\r\n",
        "\r\n",
        "    for i in categorical_columns:\r\n",
        "\r\n",
        "        nba_shots_ml = pd.get_dummies(nba_shots_ml, columns=[i], drop_first=True)\r\n",
        "\r\n",
        "    #Train/Test split\r\n",
        "\r\n",
        "    X = nba_shots_ml.loc[:, nba_shots_ml.columns != 'SHOT_MADE_FLAG']\r\n",
        "    y = nba_shots_ml['SHOT_MADE_FLAG']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
        "                                                        test_size= 0.2, \r\n",
        "                                                        random_state = 100, \r\n",
        "                                                        stratify = y,\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    # Check columns with variance equal to zero and drop them\r\n",
        "\r\n",
        "    zero_var_filter = VarianceThreshold()\r\n",
        "    X_train = zero_var_filter.fit_transform(X_train)\r\n",
        "    X_test = zero_var_filter.transform(X_test)\r\n",
        "    print('X_train e X_test possuíam', (zero_var_filter.variances_ == 0).sum(), 'atributo(s) com variância igual a zero')\r\n",
        "\r\n",
        "    print('X_train:', X_train.shape)\r\n",
        "    print('X_test:', X_test.shape)\r\n",
        "    print('y_train:', y_train.shape)\r\n",
        "    print('y_test:', y_test.shape)\r\n",
        "\r\n",
        "    # Normalize the data\r\n",
        "\r\n",
        "    scaler = StandardScaler().fit(X_train)\r\n",
        "    X_train = scaler.transform(X_train)\r\n",
        "    X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "    return X_train, X_test, y_train, y_test\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = choose_player('Blake Griffin')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função choose_player_and_shot_type"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Due to the large amount of the dataset, everything past this point you be done per player. The function below creates a sub dataset from nba_shots with the data form the chosen player. \r\n",
        "\r\n",
        "def choose_player_and_shot_type (player_name, shot_type):\r\n",
        "    player_shots = nba_shots[(nba_shots['PLAYER_NAME'] == player_name) & (nba_shots['SHOT_TYPE'] == shot_type)]\r\n",
        "    print(player_shots.head())\r\n",
        "    \r\n",
        "    # Dimensional Reduction: Columns PLAYER_ID and PLAYER_NAME carry the same type of information, PLAYER_NAME is going to be droped. \r\n",
        "    # The same happens to columns EVENT_TYPE and SHOT_MADE_FLAG, EVENT_TYPE is going to be droped.\r\n",
        "    # It also happens for TEAM_ID and TEAM_NAME, TEAM_NAME is going to be droped.\r\n",
        "\r\n",
        "    nba_shots_ml = player_shots.drop(['PLAYER_NAME', 'EVENT_TYPE', 'TEAM_NAME'], axis = 1)\r\n",
        "    \r\n",
        "    # Apply Dummy Coding to the categorial attributes of the dataset\r\n",
        "\r\n",
        "    categorical_columns = ['GRID_TYPE', 'ACTION_TYPE', 'SHOT_TYPE', 'SHOT_ZONE_BASIC', \r\n",
        "    'SHOT_ZONE_AREA', 'SHOT_ZONE_RANGE', 'HTM', 'VTM', 'SEASON_ID']\r\n",
        "\r\n",
        "    for i in categorical_columns:\r\n",
        "\r\n",
        "        nba_shots_ml = pd.get_dummies(nba_shots_ml, columns=[i], drop_first=True)\r\n",
        "\r\n",
        "    #Train/Test split\r\n",
        "\r\n",
        "    X = nba_shots_ml.loc[:, nba_shots_ml.columns != 'SHOT_MADE_FLAG']\r\n",
        "    y = nba_shots_ml['SHOT_MADE_FLAG']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
        "                                                        test_size= 0.2, \r\n",
        "                                                        random_state = 100, \r\n",
        "                                                        stratify = y,\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    # Check columns with variance equal to zero and drop them\r\n",
        "\r\n",
        "    zero_var_filter = VarianceThreshold()\r\n",
        "    X_train = zero_var_filter.fit_transform(X_train)\r\n",
        "    X_test = zero_var_filter.transform(X_test)\r\n",
        "    print('X_train e X_test possuíam', (zero_var_filter.variances_ == 0).sum(), 'atributo(s) com variância igual a zero')\r\n",
        "\r\n",
        "    print('X_train:', X_train.shape)\r\n",
        "    print('X_test:', X_test.shape)\r\n",
        "    print('y_train:', y_train.shape)\r\n",
        "    print('y_test:', y_test.shape)\r\n",
        "\r\n",
        "    # Normalize the data\r\n",
        "\r\n",
        "    scaler = StandardScaler().fit(X_train)\r\n",
        "    X_train = scaler.transform(X_train)\r\n",
        "    X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "    return X_train, X_test, y_train, y_test\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = choose_player_and_shot_type('Stephen Curry', '3PT Field Goal')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função choose_season"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Due to the large amount of the dataset, everything past this point you be done per season. The function below creates a sub dataset from nba_shots with the data form the chosen season. \r\n",
        "\r\n",
        "def choose_season (season_id):\r\n",
        "    season_shots = nba_shots[nba_shots['SEASON_ID'] == season_id]\r\n",
        "    print(season_shots.head())\r\n",
        "    \r\n",
        "    # Dimensional Reduction: Columns PLAYER_ID and PLAYER_NAME carry the same type of information, PLAYER_NAME is going to be droped. \r\n",
        "    # The same happens to columns EVENT_TYPE and SHOT_MADE_FLAG, EVENT_TYPE is going to be droped.\r\n",
        "    # It also happens for TEAM_ID and TEAM_NAME, TEAM_NAME is going to be droped.\r\n",
        "\r\n",
        "    nba_shots_ml = season_shots.drop(['PLAYER_NAME', 'EVENT_TYPE', 'TEAM_NAME'], axis = 1)\r\n",
        "    \r\n",
        "    # Apply Dummy Coding to the categorial attributes of the dataset\r\n",
        "\r\n",
        "    categorical_columns = ['GRID_TYPE', 'ACTION_TYPE', 'SHOT_TYPE', 'SHOT_ZONE_BASIC', \r\n",
        "    'SHOT_ZONE_AREA', 'SHOT_ZONE_RANGE', 'HTM', 'VTM', 'SEASON_ID']\r\n",
        "\r\n",
        "    for i in categorical_columns:\r\n",
        "\r\n",
        "        nba_shots_ml = pd.get_dummies(nba_shots_ml, columns=[i], drop_first=True)\r\n",
        "\r\n",
        "    #Train/Test split\r\n",
        "\r\n",
        "    X = nba_shots_ml.loc[:, nba_shots_ml.columns != 'SHOT_MADE_FLAG']\r\n",
        "    y = nba_shots_ml['SHOT_MADE_FLAG']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
        "                                                        test_size= 0.2, \r\n",
        "                                                        random_state = 100, \r\n",
        "                                                        stratify = y\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    # Check columns with variance equal to zero and drop them\r\n",
        "\r\n",
        "    zero_var_filter = VarianceThreshold()\r\n",
        "    X_train = zero_var_filter.fit_transform(X_train)\r\n",
        "    X_test = zero_var_filter.transform(X_test)\r\n",
        "    print('X_train e X_test possuíam', (zero_var_filter.variances_ == 0).sum(), 'atributo(s) com variância igual a zero')\r\n",
        "\r\n",
        "    print('X_train:', X_train.shape)\r\n",
        "    print('X_test:', X_test.shape)\r\n",
        "    print('y_train:', y_train.shape)\r\n",
        "    print('y_test:', y_test.shape)\r\n",
        "\r\n",
        "    # Normalize the data\r\n",
        "\r\n",
        "    scaler = StandardScaler().fit(X_train)\r\n",
        "    X_train = scaler.transform(X_train)\r\n",
        "    X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "    return X_train, X_test, y_train, y_test\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = choose_season('2020-21')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos de Machine Learning\r\n",
        "\r\n",
        "    Todos os modelos de machine learning que serão usados nesse trabalho são do tipo supervisionado e de classificação. A escolha de quais tipos de modelos usar passa pela natureza dos dados que serão trabalhados como também o que deseja-se ser capaz de prever com tais modelos.\r\n",
        "\r\n",
        "    Nós estamos trabalhando com um dataset de arremessos de jogadores da NBA. O nosso conjunto possui o resultado de cada arremesso logo, faz sentido usarmos modelos supervisionados, aqueles que são treinados tendo conhecimento do resultado de cada registro a ser usado no treinamento. \r\n",
        "\r\n",
        "    Dentro do grupo de modelos supervisionados, utilizaremos os de classificação já que, nosso intuito é poder prever se um arremesso entrou ou não."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\r\n",
        "    "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict SVM model with hyperparameter tuning (GridSearchCV)\r\n",
        "\r\n",
        "def train_svm_GS(X_train, X_test, y_test):\r\n",
        "    tuned_parameters = [{'kernel': ['rbf', 'poly', 'sigmoid'],\r\n",
        "                        'gamma': [1e-1, 1e-2, 1e-3, 1e-4],\r\n",
        "                        'C': [0.1, 1, 10, 100, 1000]\r\n",
        "                        }]\r\n",
        "                        \r\n",
        "    print(\"Hyperparameter Tuning for accuracy\")\r\n",
        "    print()\r\n",
        "\r\n",
        "    model = GridSearchCV(SVC(random_state=100), \r\n",
        "                            tuned_parameters, \r\n",
        "                            scoring='accuracy',\r\n",
        "                            )\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "    return model\r\n",
        "\r\n",
        "model_SVM_GS = train_svm_GS(X_train, X_test, y_test)\r\n",
        "y_pred_SVM_GS = model_SVM_GS.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred_SVM_GS))\r\n",
        "print()\r\n",
        "print(\"BEST TUNED PARAMETERS\", model_SVM_GS.best_params_)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate SVM model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def evaluate_SVM_GS(y_test, y_pred_SVM_GS):\r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_SVM_GS)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_SVM_GS)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_SVM_GS)\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_SVM_GS, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX SVM')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "\r\n",
        "evaluate_SVM_GS(y_test, y_pred_SVM_GS)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict SVM model\r\n",
        "\r\n",
        "def train_SVM(X_train, y_train):\r\n",
        "  model = SVC(random_state=100,\r\n",
        "              C=100,\r\n",
        "              gamma=0.0001,\r\n",
        "              kernel='rbf'\r\n",
        "              )\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  return model\r\n",
        "\r\n",
        "model_SVM = train_SVM(X_train, y_train)\r\n",
        "y_pred_SVM = model_SVM.predict(X_test)\r\n",
        "\r\n",
        "train_SVM(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate SVM model\r\n",
        "\r\n",
        "def evaluate_SVM(X_test, y_test):\r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_SVM)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_SVM)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_SVM)\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_SVM, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX SVM')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "\r\n",
        "evaluate_SVM(X_test, y_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict Decision Tree model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def train_DT_GS(X_train, X_test, y_test):\r\n",
        "\r\n",
        "    tuned_parameters = [{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \r\n",
        "                            'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}]\r\n",
        "\r\n",
        "    print(\"Hyperparameter Tuning for accuracy\")\r\n",
        "    print()\r\n",
        "\r\n",
        "    model = GridSearchCV(DecisionTreeClassifier(random_state=100), tuned_parameters, scoring='f1')\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "    return model\r\n",
        "\r\n",
        "model_DT_GS = train_DT_GS(X_train, X_test, y_test)\r\n",
        "y_pred_DT_GS = model_DT_GS.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred_DT_GS))\r\n",
        "print()\r\n",
        "print(\"BEST TUNED PARAMETERS\", model_DT_GS.best_params_)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate Decision Tree model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def evaluate_DT_GS(y_test, y_pred_DT_GS):  \r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_DT_GS)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_DT_GS)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_DT_GS, average='weighted')\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_DT_GS, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX DECISION TREE')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "evaluate_DT_GS(y_test, y_pred_DT_GS)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict Decision Tree model\r\n",
        "\r\n",
        "def train_DT(X_train, y_train):\r\n",
        "  model = DecisionTreeClassifier(max_depth = 5, \r\n",
        "                                  min_samples_leaf = 5,\r\n",
        "                                  min_samples_split = 10, \r\n",
        "                                  random_state=100\r\n",
        "                                  )\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  return model\r\n",
        "\r\n",
        "model_DT = train_DT(X_train, y_train)\r\n",
        "y_pred_DT = model_DT.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate Decision Tree model\r\n",
        "\r\n",
        "def evaluate_DT_GS(y_test, y_pred_DT):\r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_DT)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_DT)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_DT, average='weighted')\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_DT, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX DECISION TREE')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "evaluate_DT_GS(y_test, y_pred_DT)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot decision tree\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 10))\r\n",
        "tree.plot_tree(model_DT, class_names=[\"OUT\", \"IN\"], filled=True, rounded=True);"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict Random Forest model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def train_RF_GS(X_train, X_test, y_test):\r\n",
        "\r\n",
        "    tuned_parameters = [{'n_estimators': [20, 50, 100, 150, 200, 300, 400, 500],\r\n",
        "                        'max_features': [3,4,8,9,10,11],\r\n",
        "                        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\r\n",
        "                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}]\r\n",
        "\r\n",
        "    print(\"Hyperparameter Tuning for accuracy\")\r\n",
        "    print()\r\n",
        "\r\n",
        "    model = GridSearchCV(RandomForestClassifier(n_jobs=50, verbose=1, random_state=100), \r\n",
        "                        tuned_parameters, \r\n",
        "                        scoring='accuracy'\r\n",
        "                        )\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "    return model\r\n",
        "\r\n",
        "model_RF_GS = train_RF_GS(X_train, X_test, y_test)\r\n",
        "y_pred_RF_GS = model_RF_GS.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred_RF_GS))\r\n",
        "print()\r\n",
        "print(\"BEST TUNED PARAMETERS\", model_RF_GS.best_params_)\r\n",
        "\r\n",
        "train_RF_GS(X_train, X_test, y_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate Random Forest model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def evaluate_RF_GS(y_test, y_pred_RF_GS):  \r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_RF_GS)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_RF_GS)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_RF_GS, average='weighted')\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_RF_GS, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX RANDOM FOREST')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "evaluate_RF_GS(y_test, y_pred_RF_GS)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict Random Forest model\r\n",
        "\r\n",
        "def train_RF(X_train, y_train):\r\n",
        "  model = RandomForestClassifier(random_state=100,\r\n",
        "                                min_samples_leaf=8,\r\n",
        "                                min_samples_split=10,\r\n",
        "                                max_depth=12,\r\n",
        "                                max_features='auto', \r\n",
        "                                n_estimators=5000,\r\n",
        "                                n_jobs=100, \r\n",
        "                                verbose=1\r\n",
        "                                )\r\n",
        "  model.fit(X_train, y_train);\r\n",
        "  return model\r\n",
        "\r\n",
        "model_RF = train_RF(X_train, y_train)\r\n",
        "y_pred_RF = model_RF.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate Random Forest model\r\n",
        "\r\n",
        "def evaluate_RF(y_test, y_pred_RF):  \r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_RF)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_RF)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_RF, average='weighted')\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_RF, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX RANDOM FOREST')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "evaluate_RF(y_test, y_pred_RF)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_RF.feature_importances_"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot the importance of the attributes to the model\r\n",
        "\r\n",
        "importances = model_RF.feature_importances_\r\n",
        "std = np.std([tree.feature_importances_ for tree in model_RF.estimators_],\r\n",
        "             axis=0)\r\n",
        "indices = np.argsort(importances)\r\n",
        "\r\n",
        "plt.figure(figsize=(20,50))\r\n",
        "plt.title(\"FEATURE IMPORTANCES RANDOM FOREST\")\r\n",
        "plt.barh(range(X_train.shape[1]), importances[indices],\r\n",
        "       color=\"g\", align=\"center\")\r\n",
        "plt.yticks(range(X_train.shape[1]), indices)\r\n",
        "plt.ylim([-1, X_train.shape[1]])\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict XGBOOST model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "tuned_parameters = {\r\n",
        "                    #'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9],\r\n",
        "                    #'max_depth': [4,5,6,7,8,9,10,11,12], \r\n",
        "                    #'alpha': [10,20,50,100,500],\r\n",
        "                    #'lambda': [5,6,7,8,9,10,11,12,13,14,15,17,18,19,20],\r\n",
        "                    #'min_child_weight': [1,2,3,4,5,6],\r\n",
        "                    #'colsample_bytree': [0.5,0.6,0.7,0.8,0.9],\r\n",
        "                    #'subsample': [0.5,0.6,0.7,0.8,0.9],\r\n",
        "                    #'gamma': [0,0.1,0.2,0.3,0.4],\r\n",
        "                    #'n_estimators': [50, 100, 200, 300, 400, 500, 1000]\r\n",
        "                    }\r\n",
        "\r\n",
        "print('Hyperparameter Tuning for accuracy')\r\n",
        "\r\n",
        "model_XGB_GS = GridSearchCV(xgb.XGBClassifier(\r\n",
        "                                            n_estimators=1000, \r\n",
        "                                            objective=\"reg:logistic\",\r\n",
        "                                            use_label_encoder=False,\r\n",
        "                                            booster='gbtree',\r\n",
        "                                            reg_alpha=1e-5, \r\n",
        "                                            alpha=10, \r\n",
        "                                            max_depth=10,\r\n",
        "                                            gamma=0,\r\n",
        "                                            #colsample_bytree=0.8,\r\n",
        "                                            min_child_weight=5,\r\n",
        "                                            learning_rate=0.1,\r\n",
        "                                            scale_pos_weight = 1,\r\n",
        "                                            #subsample=0.8,\r\n",
        "                                            random_state=100), \r\n",
        "                                            tuned_parameters,\r\n",
        "                                            scoring='f1'\r\n",
        "                                            )\r\n",
        "model_XGB_GS.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred_XGB_GS = model_XGB_GS.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred_XGB_GS))\r\n",
        "print()\r\n",
        "print(\"BEST TUNED PARAMETERS\", model_XGB_GS.best_params_)\r\n",
        "                    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate XGBOOST model with hyper-parameters tuning (GridSearchCV)\r\n",
        "\r\n",
        "def evaluate_XGB_CV(y_test, y_pred_XGB_GS):\r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_XGB_GS)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_XGB_GS)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_XGB_GS)\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_XGB_GS, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "\r\n",
        "evaluate_XGB_CV(y_test, y_pred_XGB_GS)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Train and predict XGBOOST model\r\n",
        "\r\n",
        "def train_XGB (X_train, y_train):\r\n",
        "    model = xgb.XGBClassifier(n_estimators=5000, \r\n",
        "                              objective=\"reg:logistic\",\r\n",
        "                              use_label_encoder=False,\r\n",
        "                              booster='gbtree', \r\n",
        "                              #reg_alpha=100,\r\n",
        "                              alpha=10, \r\n",
        "                              max_depth=12,\r\n",
        "                              gamma=0,\r\n",
        "                              colsample_bytree=0.8,\r\n",
        "                              min_child_weight=5,\r\n",
        "                              learning_rate=0.01,\r\n",
        "                              scale_pos_weight = 1,\r\n",
        "                              #subsample=0.7,\r\n",
        "                              random_state=100)\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "    return model\r\n",
        "\r\n",
        "model_XGB = train_XGB(X_train, y_train)\r\n",
        "y_pred_XGB = model_XGB.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate XGBOOST model\r\n",
        "\r\n",
        "def evaluate_XGB(X_test, y_test):\r\n",
        "\r\n",
        "  # Acurácia\r\n",
        "  from sklearn.metrics import accuracy_score\r\n",
        "  accuracy = accuracy_score(y_test, y_pred_XGB)\r\n",
        "  print('Acurácia: ', accuracy)\r\n",
        "\r\n",
        "  # Kappa\r\n",
        "  from sklearn.metrics import cohen_kappa_score\r\n",
        "  kappa = cohen_kappa_score(y_test, y_pred_XGB)\r\n",
        "  print('Kappa: ', kappa)\r\n",
        "\r\n",
        "  # F1\r\n",
        "  from sklearn.metrics import f1_score\r\n",
        "  f1 = f1_score(y_test, y_pred_XGB)\r\n",
        "  print('F1: ', f1)\r\n",
        "\r\n",
        "  # Matriz de confusão\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  confMatrix = confusion_matrix(y_pred_XGB, y_test)\r\n",
        "\r\n",
        "  plt.figure(figsize=(20,12))\r\n",
        "  ax = plt.subplot()\r\n",
        "  sns.heatmap(confMatrix, annot=True, fmt=\".0f\", cmap =\"YlGnBu\", annot_kws={\"fontsize\":20})\r\n",
        "  plt.xlabel('REAL')\r\n",
        "  plt.ylabel('PRED')\r\n",
        "  plt.title('CONFUSION MATRIX XGBOOST')\r\n",
        "\r\n",
        "  # Colocar os nomes\r\n",
        "  ax.xaxis.set_ticklabels(['OUT', 'IN']) \r\n",
        "  ax.yaxis.set_ticklabels(['OUT', 'IN'])\r\n",
        "\r\n",
        "evaluate_XGB(X_test, y_test)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot the importance of the attributes to the model\r\n",
        "\r\n",
        "xgb.plot_importance(model_XGB)\r\n",
        "plt.rcParams['figure.figsize'] = [30, 30]\r\n",
        "plt.show()\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# SHOT TYPE BAR PLOT BLAKE GRIFFIN\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "fig10 = sns.countplot(data=nba_shots, x=nba_shots[nba_shots['PLAYER_NAME'] == 'Blake Griffin']['SHOT_TYPE'], palette = 'husl')\r\n",
        "fig10.set_xlabel('SHOT_TYPE', fontsize=20)\r\n",
        "fig10.set_ylabel('COUNT', fontsize=20)\r\n",
        "fig10.tick_params(labelsize=20)\r\n",
        "plt.title('SHOT TYPE', fontsize = 20)\r\n",
        "for p in fig10.patches:\r\n",
        "    txt = str(p.get_height().round(2))\r\n",
        "    txt_x = p.get_x() \r\n",
        "    txt_y = p.get_height()\r\n",
        "    fig10.text(txt_x,txt_y,txt)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão\r\n",
        "\r\n",
        "Após a avaliação de todos os modelos treinados, ficou claro que os modelos do tipo Comitê são os melhores entre os testados. Random Forest Classifier, que utiliza o método de bagging e XGBOOST, que utiliza boosting, foram os que obtiveram as melhores performances. Os resultados foram os esperados se considerarmos que os modelos do tipo Comitê são reconhecidamente bons para cenários onde temos um conjunto muito grande de dados e o problema é muito complexo. A complexidade do problema é um fator a ser bastante considerado pois, estamos tratando de de um tipo de evento, arremesso de basquete, que possui ínumeras variáveis que compõe e afetam o resultado.\r\n",
        "\r\n",
        "Esses resultados corroboram o favoritismo desses tipos de modelos para a previsão de arremessos. Resultados semelhantes foram encontrados por Brett Meehan em \"Predicting NBA Shots\" e Max Murakami-Moses em \"Analysis of Machine Learning Models Predicting Basketball Shot Success\". Vale reassaltar que, apesar de próximos e indicarem um mesmo caminho, os resultados obtidos nesse estudo e nos mencionados foram diferentes e isso era esperado, visto que estamos falando de bases de dados que se diferenciam em quandidade e qualidade de atributos e quantidade de registros disponíveis. Além do fato principal que aqui, focamos em realizar o treinmanto de modelos usando dados de jogadores separadamente euquanto os outros trabalharam, com o conjunto de uma ou mais temporadas inteiras para o treinamento e previsão de seus modelos.  [7][8]\r\n",
        "\r\n",
        "Outro resultado interessante foi perceber que comparando as previsões dos arremessos de 2 e 3 pontos de Stephen Curry separadamante e depois compararando com as previsões dos arremessos de Blake Griffin, que arremessou quase que exclusivamente bolas de 2 na maior parte de sua carreira, que os modelos cujo os conjuntos de Treino e Teste possuiam em sua maioria ou exclusivamente arremressos de 2 pontos e de um tipo bem específico, obtiveram performance superior comparados aos outros cenários apresentados. Isso nos leva a crer que a grande complexidade e variedade associada a um arremesso de basquete e todos os fatores que entram em consideração, limitam a performance dos modelos de machine learning e que um caminho possível para obter melhores resultados seja a segmentação dos arremessos em suas diferentes categorias e tratá-los como problemas de previsão independentes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\r\n",
        "\r\n",
        "    [1] Stephen Curry career stats. https://www.basketball-reference.com/players/c/curryst01.html, 2021.\r\n",
        "\r\n",
        "    [2] NBA & ABA Career Leaders and Records for 3-Pt Field Goal Pct. https://www.basketball-reference.com/leaders/fg3_pct_career.html, 2021.\r\n",
        "\r\n",
        "    [3] Support Vector Classifier. https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html, 2021.\r\n",
        "\r\n",
        "    [4] Decision Tree Classifier. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html, 2021.\r\n",
        "\r\n",
        "    [5] Random Forest Classifier. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html, 2021.\r\n",
        "\r\n",
        "    [6] XGBOOST. https://xgboost.readthedocs.io/en/latest/, 2021.\r\n",
        "\r\n",
        "    [7] B. Meehan. Predicting NBA Shots. http://cs229.stanford.edu/proj2017/final-reports/5132133.pdf, 2017.\r\n",
        "\r\n",
        "    [8] M. Murakami-Moses. Analysis of Machine Learning Models Predicting Basketball Shot Success. https://www.the-iyrc.org/uploads/1/2/9/7/129787256/20_iyrc2020_35_final.pdf."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}